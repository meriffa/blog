# .NET Core Concepts (SIMD, AVX, Intrinsics)

This article provides an introduction to SIMD, AVX and Hardware Intrinsics in .NET Core.

## SIMD & AVX Introduction

[Single Instruction, Multiple Data (SIMD)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) is an instruction set extension available on Intel and AMD processors, which allows a single instruction to be performed on multiple data objects. SIMD is sometimes referred to as vectorization, where a single operation is applied to a vector of values instead of a single value.

There have been multiple sets of SIMD instructions introduced over the years - MMX, SSE2, SSE3, SSSE3, SSE4, AVX, AVX2, AVX-512 and AVX10. This article focuses on [Advanced Vector Extensions (AVX)](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions), [AVX2](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#Advanced_Vector_Extensions_2) and [AVX-512](https://en.wikipedia.org/wiki/AVX-512). All extensions prior to AVX are considered legacy.

The legacy SIMD SSE extension provides 8 new 128-bit (`XMM0-XMM7`) registers. The AVX extension extends these registers to 256-bit and increases the number to 16 (`YMM0-YMM15`). The AVX-512 extension extends these registers to 512-bit and increases the number to 32 (`ZMM0-ZMM31`). AVX-512 also introduces 8 new up to 64-bit opmask registers (`k0-k7`).

AVX introduces a three-operand SIMD instruction format ([VEX Coding Scheme](https://en.wikipedia.org/wiki/VEX_prefix)). Here is an example of such an instruction:

```vpaddd ymm0, ymm1, ymm2```

The `VPADDD` instruction performs a SIMD add of the packed integers from the first source operand (`YMM1`) and the second source operand (`YMM2`), and stores the packed integer results in the destination operand (`YMM0`). The result is 8 32-bit integers in this case.

## Hardware Intrinsics In .NET Core Introduction

Intrinsics are small functions that are intended to be replaced with one or more (.NET Core) assembly instructions by the compiler. Hardware Intrinsics were introduced in .NET Core 3.0. This feature provides .NET with access to most of the hardware SIMD extensions. The Hardware Intrinsics are part of `System.Numerics` and `System.Runtime.Intrinsics` namespaces and can be divided into three parts:

* Data: `Vector<T>`, `Vector128<T>`, `Vector256<T>`, `Vector512<T>`
* Hardware Independent Operations: `Vector`, `Vector128`, `Vector256`, `Vector512`
* Hardware Specific Operations: `Avx`, `Avx2`, `Avx512F`, `Avx512BW`, `Avx512DQ`, `Avx512CD`, `Avx512Vbmi`, `Avx10v1`

The data types are structures that represent variable (`Vector<T>`) or fixed size (`Vector128<T>`, `Vector256<T>` and `Vector512<T>`) vectors. The Hardware Operation types provide mapping to specific SIMD operations using vectors. The Hardware Independent Operations provide emulation in case the processor does not support specific operations. The Hardware Specific Operations target specific hardware SIMD extensions.

## Reference Implementation (Sum)

Let's start with the following C# function that returns the sums of span of integers:

```
private static int SumLoop(ReadOnlySpan<int> region)
{
    var result = 0;
    for (var i = 0; i < region.Length; i++)
        result += region[i];
    return result;
}
```

The method implements a trivial approach to calculating a sum of sequence of integers using a temporary variable and `for` loop. To take advantage of SIMD capabilities in .NET and the processor, we can vectorize the `SumLoop()` method using variable SIMD logic as follows:

```
private static int SumVector(ReadOnlySpan<int> region)
{
    var vector = Vector<int>.Zero;
    for (int i = 0, count = region.Length - Vector<int>.Count; i <= count; i += Vector<int>.Count)
        vector += new Vector<int>(region[i..]);
    var result = Vector.Dot(vector, Vector<int>.One);
    for (var i = region.Length - (region.Length % Vector<int>.Count); i < region.Length; i++)
        result += region[i];
    return result;
}
```

The vectorized `SumVector()` method also uses a temporary variable, but has two parts. The first part is the `for (int i = 0, count ...` loop, which uses SIMD operations to calculate the sum. The second part is the `for (var i = region.Length ...` loop, which calculates the sum of the remaining elements in the sequence if the length of the sequence is not a multiple of the size (`Vector<int>.Count`) of the SIMD vector.

> [!NOTE]
> The `Vector.Dot(vector, Vector<int>.One)` dot-product statement is used to calculate the sum of all individual `vector` components (e.g. horizontal add).

On platforms where AVX2 is available (Intel Haswell (Q2 2013) and newer, AMD Excavator (Q2 2015) and newer), we can vectorize the `SumLoop()` method using AVX2 as follows:

```
private unsafe int SumAvx2(ReadOnlySpan<int> region)
{
    var vector = Vector256<int>.Zero;
    fixed (int* pRegion = region)
        for (int i = 0, count = region.Length - Vector256<int>.Count; i <= count; i += Vector256<int>.Count)
            vector = Avx2.Add(vector, Avx.LoadVector256(pRegion + i));
    var result = Vector256.Dot(vector, Vector256<int>.One);
    for (var i = region.Length - (region.Length % Vector256<int>.Count); i < region.Length; i++)
        result += region[i];
    return result;
}
```

The AVX2 vectorized `SumAvx2()` method is very similar to the variable SIMD `SumVector()` method except that it uses `Vector256<int>` instead of `Vector<int>` and `Avx.LoadVector256()` to construct and `Avx2.Add()` to add 256-bit vectors.

> [!NOTE]
> The `SumAvx2` method is marked as `unsafe`, because it uses pointer required by the `Avx.LoadVector256()` function.

On platforms where AVX5-12 is available (Intel Tiger Lake (2020) and newer, AMD Zen 4 (2022) and newer), we can vectorize the `SumLoop()` method using AVX-512 as follows:

```
private unsafe int SumAvx512(ReadOnlySpan<int> region)
{
    var vector = Vector512<int>.Zero;
    fixed (int* pRegion = region)
        for (int i = 0, count = region.Length - Vector512<int>.Count; i <= count; i += Vector512<int>.Count)
            vector = Avx512F.Add(vector, Avx512F.LoadVector512(pRegion + i));
    var result = Vector512.Dot(vector, Vector512<int>.One);
    for (var i = region.Length - (region.Length % Vector512<int>.Count); i < region.Length; i++)
        result += region[i];
    return result;
}
```

The AVX-512 vectorized `SumAvx512()` method is very similar to the AVX2 method `SumAvx2()` except that it uses `Vector512<int>` instead of `Vector256<int>` and `Avx512F` instead of `Avx/Avx2` to process 512-bit vectors.

> [!NOTE]
> The AVX-512 extension consists of multiple groups of extensions where the most common are - Foundation (F), Conflict Detection (CD), Byte & Word (BW), Doubleword & Quadword Instructions (DQ), Vector Length (VL) and Vector Byte Manipulation Instructions (VBMI).

As an optional step, we can confirm that our .NET code is using the native AVX2 / AVX-512 instructions by displaying the `SumAvx2()` / `SumAvx512()` method disassembly. We can use either the `DOTNET_JitDisasm` switch or capture a core dump and display the method assembly code using LLDB and `clru`. The latter is much more accurate. Using `clru` for `SumAvx2()` we get the following:

```
Normal JIT generated code
ByteZoo.Blog.App.Controllers.Concepts.IntrinsicsController.SumAvx2(System.ReadOnlySpan`1<Int32>)
ilAddr is 00007FBB68DA6474 pImport is 00000000237F11B0
Begin 00007FBAEA671F80, size 2d5

/home/marian/Development/ByteZoo.Blog/Sources/ByteZoo.Blog.App/Controllers/Concepts/IntrinsicsController.cs @ 419:
00007fbaea671f80 55                   push    rbp
00007fbaea671f81 4881ec40020000       sub     rsp, 0x240
00007fbaea671f88 488dac2440020000     lea     rbp, [rsp + 0x240]
00007fbaea671f90 33c0                 xor     eax, eax
00007fbaea671f92 48898548feffff       mov     qword ptr [rbp - 0x1b8], rax
00007fbaea671f99 c4413857c0           vxorps  xmm8, xmm8, xmm8
00007fbaea671f9e 48b880feffffffffffff movabs  rax, -0x180
00007fbaea671fa8 c5797f4405d0         vmovdqa xmmword ptr [rbp + rax - 0x30], xmm8
00007fbaea671fae c5797f4405e0         vmovdqa xmmword ptr [rbp + rax - 0x20], xmm8
00007fbaea671fb4 c5797f4405f0         vmovdqa xmmword ptr [rbp + rax - 0x10], xmm8
00007fbaea671fba 4883c030             add     rax, 0x30
00007fbaea671fbe 75e8                 jne     0x7fbaea671fa8
00007fbaea671fc0 48897df8             mov     qword ptr [rbp - 0x8], rdi
00007fbaea671fc4 488975e8             mov     qword ptr [rbp - 0x18], rsi
00007fbaea671fc8 488955f0             mov     qword ptr [rbp - 0x10], rdx
00007fbaea671fcc 833d2d54040000       cmp     dword ptr [rip + 0x4542d], 0x0
00007fbaea671fd3 7405                 je      0x7fbaea671fda
00007fbaea671fd5 e856f92e7e           call    0x7fbb68961930 (JitHelp: CORINFO_HELP_DBG_IS_JUST_MY_CODE)
00007fbaea671fda 90                   nop     

/home/marian/Development/ByteZoo.Blog/Sources/ByteZoo.Blog.App/Controllers/Concepts/IntrinsicsController.cs @ 420:
00007fbaea671fdb c5fc57c0             vxorps  ymm0, ymm0, ymm0
00007fbaea671fdf c5fc118550ffffff     vmovups ymmword ptr [rbp - 0xb0], ymm0
00007fbaea671fe7 c5fc108550ffffff     vmovups ymm0, ymmword ptr [rbp - 0xb0]
00007fbaea671fef c5fc1145b0           vmovups ymmword ptr [rbp - 0x50], ymm0

...

/home/marian/Development/ByteZoo.Blog/Sources/ByteZoo.Blog.App/Controllers/Concepts/IntrinsicsController.cs @ 423:
00007fbaea672057 c5fc1045b0           vmovups ymm0, ymmword ptr [rbp - 0x50]
00007fbaea67205c c5fc118510ffffff     vmovups ymmword ptr [rbp - 0xf0], ymm0
00007fbaea672064 8b4594               mov     eax, dword ptr [rbp - 0x6c]
00007fbaea672067 4898                 cdqe    
00007fbaea672069 b904000000           mov     ecx, 0x4
00007fbaea67206e 4863c9               movsxd  rcx, ecx
00007fbaea672071 480fafc1             imul    rax, rcx
00007fbaea672075 488b4da0             mov     rcx, qword ptr [rbp - 0x60]
00007fbaea672079 c5fc100408           vmovups ymm0, ymmword ptr [rax + rcx]
00007fbaea67207e c5fc1185f0feffff     vmovups ymmword ptr [rbp - 0x110], ymm0
00007fbaea672086 c5fc108510ffffff     vmovups ymm0, ymmword ptr [rbp - 0xf0]
00007fbaea67208e c5fdfe85f0feffff     vpaddd  ymm0, ymm0, ymmword ptr [rbp - 0x110]
00007fbaea672096 c5fc1185d0feffff     vmovups ymmword ptr [rbp - 0x130], ymm0
00007fbaea67209e c5fc1085d0feffff     vmovups ymm0, ymmword ptr [rbp - 0x130]
00007fbaea6720a6 c5fc1145b0           vmovups ymmword ptr [rbp - 0x50], ymm0

...

/home/marian/Development/ByteZoo.Blog/Sources/ByteZoo.Blog.App/Controllers/Concepts/IntrinsicsController.cs @ 424:
00007fbaea6720ee c5fc1045b0           vmovups ymm0, ymmword ptr [rbp - 0x50]
00007fbaea6720f3 c5fc118590feffff     vmovups ymmword ptr [rbp - 0x170], ymm0
00007fbaea6720fb c5fc10055d010000     vmovups ymm0, ymmword ptr [rip + 0x15d]
00007fbaea672103 c5fc118570feffff     vmovups ymmword ptr [rbp - 0x190], ymm0
00007fbaea67210b c5fc108590feffff     vmovups ymm0, ymmword ptr [rbp - 0x170]
00007fbaea672113 c4e27d408570feffff   vpmulld ymm0, ymm0, ymmword ptr [rbp - 0x190]
00007fbaea67211c c5fc118510feffff     vmovups ymmword ptr [rbp - 0x1f0], ymm0
00007fbaea672124 c5fc108510feffff     vmovups ymm0, ymmword ptr [rbp - 0x1f0]
00007fbaea67212c c4e27d028510feffff   vphaddd ymm0, ymm0, ymmword ptr [rbp - 0x1f0]
00007fbaea672135 c5fc1185f0fdffff     vmovups ymmword ptr [rbp - 0x210], ymm0
00007fbaea67213d c5fc1085f0fdffff     vmovups ymm0, ymmword ptr [rbp - 0x210]
00007fbaea672145 c4e27d0285f0fdffff   vphaddd ymm0, ymm0, ymmword ptr [rbp - 0x210]
00007fbaea67214e c5fc1185d0fdffff     vmovups ymmword ptr [rbp - 0x230], ymm0
00007fbaea672156 c5fc1085d0fdffff     vmovups ymm0, ymmword ptr [rbp - 0x230]
00007fbaea67215e c4e37d4685d0fdffff01 vperm2i128 ymm0, ymm0, ymmword ptr [rbp - 0x230], 0x1
00007fbaea672168 c5fdfe85d0fdffff     vpaddd  ymm0, ymm0, ymmword ptr [rbp - 0x230]
00007fbaea672170 c5f97ec0             vmovd   eax, xmm0
00007fbaea672174 89856cfeffff         mov     dword ptr [rbp - 0x194], eax
00007fbaea67217a 8b856cfeffff         mov     eax, dword ptr [rbp - 0x194]
00007fbaea672180 8945ac               mov     dword ptr [rbp - 0x54], eax

...

/home/marian/Development/ByteZoo.Blog/Sources/ByteZoo.Blog.App/Controllers/Concepts/IntrinsicsController.cs @ 428:
00007fbaea672246 8b4580               mov     eax, dword ptr [rbp - 0x80]
00007fbaea672249 c5f877               vzeroupper 
00007fbaea67224c 4881c440020000       add     rsp, 0x240
00007fbaea672253 5d                   pop     rbp
00007fbaea672254 c3                   ret     
```

> [!NOTE]
> The `clru` output shows that we are using AVX instructions - `VMOVUPS`, `VPADDD`, `VPHADDD`, etc.

In some extreme cases, we might decide to hand-craft the `SumAvx2()` method in assembly and use it via P/Invoke (`LibraryImport`). Here is an example:

C#:
```
[LibraryImport("ByteZoo.Blog.Asm.Library.so", EntryPoint = "SumAvx2_Interop", SetLastError = false)]
private static unsafe partial int SumAvx2Interop(int* pRegion, int itemCount);
```

NASM:
```
SumAvx2_Interop:        push                    rbp                                             ; int SumAvx2Interop(int* pRegion, int itemCount);
                        mov                     rbp, rsp
                        xor                     rax, rax
._pre_aligned:          test                    esi, esi
                        jz                      ._complete
                        test                    edi, 0x3F                                       ; 64-byte alignment
                        jz                      ._aligned
                        add                     eax, [rdi]
                        add                     rdi, ELEMENT_SIZE
                        dec                     esi
                        jmp                     ._pre_aligned
._aligned:              vxorps                  xmm0, xmm0, xmm0
._aligned_loop:         cmp                     esi, YMM_SIZE / ELEMENT_SIZE
                        jl                      ._post_aligned
                        vmovdqa                 ymm1, [rdi]
                        vpaddd                  ymm0, ymm0, ymm1
                        add                     rdi, YMM_SIZE
                        sub                     esi, YMM_SIZE / ELEMENT_SIZE
                        jmp                     ._aligned_loop
._post_aligned:         vphaddd                 ymm0, ymm0, ymm0
                        vmovdqu                 [rbp - YMM_SIZE], ymm0
                        add                     eax, [rbp - YMM_SIZE + 0 * ELEMENT_SIZE]
                        add                     eax, [rbp - YMM_SIZE + 1 * ELEMENT_SIZE]
                        add                     eax, [rbp - YMM_SIZE + 4 * ELEMENT_SIZE]
                        add                     eax, [rbp - YMM_SIZE + 5 * ELEMENT_SIZE]
._post_aligned_loop:    test                    esi, esi
                        jz                      ._complete
                        add                     eax, [rdi]
                        add                     rdi, ELEMENT_SIZE
                        dec                     esi
                        jmp                     ._post_aligned_loop
._complete:             pop                     rbp
                        ret

ELEMENT_SIZE            equ                     4                                               ; sizeof(int)
YMM_SIZE                equ                     32                                              ; YMM register size (256-bit)
```

> [!NOTE]
> The native `SumAvx2_Interop` function implementation needs to take into account the additional CLR interop prolog and epilog code to justify such an implementation.

The last step in optimizing the `SumLoop()` method is to compare the performance is of the different implementations. This is a critical step in this optimization process, since vectorization may not result in significant or any gains in all cases.

We use [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) to measure the performance of each `Sum()` method implementation. Here are the results for arrays of 1,003 and 1,000,003 elements:

```
| Method                      | Categories | Size    | Mean            | Error         | StdDev        | Median          | Ratio | RatioSD |
|---------------------------- |----------- |-------- |----------------:|--------------:|--------------:|----------------:|------:|--------:|
| 'Sum (Loop)'                | Sum        | 1003    |     182.1497 ns |     0.2972 ns |     0.2780 ns |     182.0790 ns | 1.000 |    0.00 |
| 'Sum (LINQ)'                | Sum        | 1003    |     184.0015 ns |     0.1720 ns |     0.1524 ns |     184.0123 ns | 1.010 |    0.00 |
| 'Sum (Unrolled)'            | Sum        | 1003    |     175.4556 ns |     0.3408 ns |     0.3021 ns |     175.3937 ns | 0.963 |    0.00 |
| 'Sum (Vector)'              | Sum        | 1003    |      56.2625 ns |     0.1178 ns |     0.1102 ns |      56.2381 ns | 0.309 |    0.00 |
| 'Sum (AVX2)'                | Sum        | 1003    |      40.3512 ns |     0.1324 ns |     0.1238 ns |      40.3803 ns | 0.222 |    0.00 |
| 'Sum (AVX2 Interop)'        | Sum        | 1003    |      42.2288 ns |     0.0991 ns |     0.0927 ns |      42.2560 ns | 0.232 |    0.00 |
| 'Sum (Loop)'                | Sum        | 1000003 | 178,678.3113 ns | 3,397.5100 ns | 3,336.8091 ns | 176,560.7798 ns | 1.000 |    0.03 |
| 'Sum (LINQ)'                | Sum        | 1000003 | 180,926.1757 ns | 2,731.4665 ns | 2,555.0155 ns | 179,617.8008 ns | 1.013 |    0.02 |
| 'Sum (Unrolled)'            | Sum        | 1000003 | 179,092.6473 ns | 3,350.8084 ns | 3,134.3483 ns | 177,205.3108 ns | 1.003 |    0.02 |
| 'Sum (Vector)'              | Sum        | 1000003 |  75,726.0582 ns |   295.6515 ns |   262.0873 ns |  75,696.3732 ns | 0.424 |    0.01 |
| 'Sum (AVX2)'                | Sum        | 1000003 |  57,746.6054 ns |   304.5115 ns |   269.9415 ns |  57,709.1494 ns | 0.323 |    0.01 |
| 'Sum (AVX2 Interop)'        | Sum        | 1000003 |  58,516.5748 ns |   203.9885 ns |   190.8110 ns |  58,507.9211 ns | 0.328 |    0.01 |
```

The benchmark results clearly show that the SIMD-based implementations provide significant improvement over the traditional implementations. E.g. the AVX2 implementation is 4.5 (1,003 elements) and 3.1 (1,000,003) times faster than the traditional implementation. The results also show that the CLR P/Invoke overhead outweighs the benefits of such implementation in this case.

> [!NOTE]
> The AVX-512 implementations are excluded, because the extensions are not supported in the benchmarking environment. See the **Emulation** section below for more details. The `Sum (LINQ)` uses a LINQ-based sum implementation (`region.Aggregate(0, (current, i) => current + i);`)

## Reference Implementation (Compare)

The SIMD instructions and Intrinsics methods are not limited to just integer and floating-point calculations. There are a number of logical operations as well (e.g. compare, shuffle, mask-based, etc.).

Let's look at the following C# function, which compares two byte sequences:

```
private static bool CompareLoop(ReadOnlySpan<byte> region1, ReadOnlySpan<byte> region2)
{
    for (var i = 0; i < region1.Length; i++)
        if (region1[i] != region2[i])
            return false;
    return true;
}
```

The `CompareLoop()` method can be vectorized as follows:

Variable SIMD:
```
private static bool CompareVector(ReadOnlySpan<byte> region1, ReadOnlySpan<byte> region2)
{
    for (int i = 0, count = region1.Length - Vector<byte>.Count; i <= count; i += Vector<byte>.Count)
        if (!Vector.EqualsAll(new Vector<byte>(region1[i..]), new Vector<byte>(region2[i..])))
            return false;
    for (var i = region1.Length - (region1.Length % Vector<byte>.Count); i < region1.Length; i++)
        if (region1[i] != region2[i])
            return false;
    return true;
}
```

AVX2:
```
private unsafe bool CompareAvx2(ReadOnlySpan<byte> region1, ReadOnlySpan<byte> region2)
{
    const int mask = unchecked((int)0xFFFF_FFFF);
    fixed (byte* pRegion1 = region1)
    fixed (byte* pRegion2 = region2)
    {
        for (int i = 0, count = region1.Length - Vector256<byte>.Count; i <= count; i += Vector256<byte>.Count)
            if (Avx2.MoveMask(Avx2.CompareEqual(Avx.LoadVector256(pRegion1 + i), Avx.LoadVector256(pRegion2 + i))) != mask)
                return false;
        for (var i = region1.Length - (region1.Length % Vector256<byte>.Count); i < region1.Length; i++)
            if (region1[i] != region2[i])
                return false;
        return true;
    }
}
```

AVX-512:
```
private unsafe bool CompareAvx512(ReadOnlySpan<byte> region1, ReadOnlySpan<byte> region2)
{
    const byte mask = 0xFF;
    fixed (byte* pRegion1 = region1)
    fixed (byte* pRegion2 = region2)
    {
        for (int i = 0, count = region1.Length - Vector512<byte>.Count; i <= count; i += Vector512<byte>.Count)
        {
            var resultVector = Avx512BW.CompareEqual(Avx512F.LoadVector512(pRegion1 + i), Avx512F.LoadVector512(pRegion2 + i));
            for (int j = 0; j < Vector512<byte>.Count; j++)
                if (resultVector[j] != mask)
                    return false;
        }
        for (var i = region1.Length - (region1.Length % Vector512<byte>.Count); i < region1.Length; i++)
            if (region1[i] != region2[i])
                return false;
        return true;
    }
}
```

The vectorized methods `CompareVector()`, `CompareAvx2()` and `CompareAvx512` show the use of logical SIMD operations (e.g. `Vector.EqualsAll()`, `Avx2.CompareEqual()`, `Avx2.MoveMask()` and `Avx512BW.CompareEqual()`).

The performance benchmarks for the `Compare()` method implementations are as follows:

```
| Method                      | Categories | Size    | Mean            | Error         | StdDev        | Median          | Ratio | RatioSD |
|---------------------------- |----------- |-------- |----------------:|--------------:|--------------:|----------------:|------:|--------:|
| 'Compare (Loop)'            | Compare    | 1003    |     298.8081 ns |     5.2352 ns |     6.9888 ns |     299.7129 ns | 1.001 |    0.03 |
| 'Compare (LINQ)'            | Compare    | 1003    |      11.2604 ns |     0.2193 ns |     0.1944 ns |      11.2867 ns | 0.038 |    0.00 |
| 'Compare (Vectors)'         | Compare    | 1003    |      30.6248 ns |     0.6379 ns |     0.6265 ns |      30.5097 ns | 0.103 |    0.00 |
| 'Compare (AVX2)'            | Compare    | 1003    |      17.6985 ns |     0.3300 ns |     0.3087 ns |      17.6225 ns | 0.059 |    0.00 |
| 'Compare (AVX2 Interop)'    | Compare    | 1003    |      19.8425 ns |     0.2953 ns |     0.2617 ns |      19.8208 ns | 0.066 |    0.00 |
| 'Compare (Loop)'            | Compare    | 1000003 | 267,676.7935 ns | 1,874.6560 ns | 1,753.5544 ns | 267,005.1797 ns | 1.000 |    0.01 |
| 'Compare (LINQ)'            | Compare    | 1000003 |  15,588.7499 ns |   277.7391 ns |   259.7973 ns |  15,648.0542 ns | 0.058 |    0.00 |
| 'Compare (Vectors)'         | Compare    | 1000003 |  23,819.1460 ns |   179.3712 ns |   159.0079 ns |  23,742.8344 ns | 0.089 |    0.00 |
| 'Compare (AVX2)'            | Compare    | 1000003 |  16,115.8759 ns |   103.9893 ns |    92.1838 ns |  16,127.4058 ns | 0.060 |    0.00 |
| 'Compare (AVX2 Interop)'    | Compare    | 1000003 |  15,451.9429 ns |   125.6245 ns |   117.5092 ns |  15,461.7520 ns | 0.058 |    0.00 |
```

The benchmark results in this case that a LINQ-based implementation is the fastest and there is no need for vectorization.

> [!NOTE]
> The LINQ-based implementation uses `region1.SequenceEqual(region2)` statement.

## Emulation (AVX, AVX2, AVX-512, AVX10)

In case you do not have access to hardware that supports a particular SIMD extension (e.g. AVX-512, AVX10), you can use [Intel Software Development Emulator (SDE)](https://software.intel.com/en-us/articles/intel-software-development-emulator) to emulate these extensions.

Once you download and extract the SDE, you can run your .NET application in the emulator as follows:

```
~/<SDE_Path>/sde64 -future -- dotnet ~/<Application_Path>/<Application>.dll <Application_Parameters>
```

> [!NOTE]
> The `<SDE_Path>` is the location where the SDE was extracted. The `<Application_Path>` is the location of the .NET application and the `<Application>.dll` and `<Application_Parameters>` are the application assembly and startup parameters. You can also change the `-future` to specify a particular Intel processor architecture.

## Conclusion

The SIMD vectorization must be taken in a broader context, not just in terms of performance. Just like any other type of performance optimization, it needs to be measured instead of assumed. Any SIMD / Hardware Intrinsics logic will increase the complexity of the solution, introduce hardware dependencies and make it more difficult to support. This type of performance optimization is only justified in cases where the performance gains clearly outweigh all other drawbacks combined.

## References

* [.NET Core Concepts](./.NET%20Core%20Concepts%20(Summary).md)
* [Advanced Vector Extensions (AVX)](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions)
* [Hardware Intrinsics in .NET Core](https://devblogs.microsoft.com/dotnet/hardware-intrinsics-in-net-core)
* [Hardware Intrinsics in .NET 8](https://devblogs.microsoft.com/dotnet/dotnet-8-hardware-intrinsics/)
* [Intel 64 and IA-32 Architectures Software Developer Manuals](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html)
* [AMD64 Architecture Programmer's Manual Volumes 1–5](https://www.amd.com/content/dam/amd/en/documents/processor-tech-docs/programmer-references/40332.pdf)
* [Article Source Code](/Sources)

<!--- Category: .NET Concepts, Tags: .NET, .NET Core, SIMD, Linux --->